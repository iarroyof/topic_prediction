{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled9.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iarroyof/topic_prediction/blob/master/Untitled9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qMxkX2ouFiA8"
      },
      "outputs": [],
      "source": [
        "!pip install stable-baselines3"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "metadata": {
        "id": "UqQzWbpWDjqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gym.core import ActionWrapper\n",
        "from scipy.sparse.bsr import bsr_matrix\n",
        "from numpy import random\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import pandas as pd\n",
        "from scipy.sparse import csr_matrix\n",
        "import numpy as np\n",
        "import operator\n",
        "import gym\n",
        "from gym import spaces\n",
        "import statistics\n",
        "import os\n",
        "from random import *\n",
        "import scipy.sparse as sparse\n",
        "from stable_baselines3 import PPO, A2C\n",
        "\n",
        "\n",
        "class Environment(gym.Env):\n",
        "\n",
        "   metadata = {'render.modes': ['human']}\n",
        "\n",
        "   def __init__(self, objeto, thd):\n",
        "    \n",
        "    self.busc = objeto\n",
        "    self.info ={}\n",
        "    self.rwd_th= thd\n",
        "    self.rwd_acc = 0\n",
        "    self.step_counter = 0\n",
        "    self.vocab_tam = self.busc.vocab_tam\n",
        "    self.vocab = self.busc.vocab_list\n",
        "    self.action_space=spaces.MultiDiscrete((self.vocab_tam,self.vocab_tam, self.vocab_tam, self.vocab_tam)) #numpy.ndarray\n",
        "    self.observation_space=gym.spaces.Box(low=0.0,high=10.0,shape=(self.vocab_tam,),dtype=np.float32) #numpy.ndarray\n",
        " \n",
        "  \n",
        "   def set_complexity(self, complejidad):\n",
        "      self.complej_usr = complejidad\n",
        "\n",
        "   def set_topics(self, temas):\n",
        "     self.temas = temas\n",
        "\n",
        "   def step(self,action):  #action =numpy.ndarray\n",
        "     if isinstance(action, tuple):\n",
        "        action = action[0]\n",
        "     action_list = action.tolist()\n",
        "     list_vocab= [self.vocab[index] for index in action]\n",
        "     self.temas = ' '.join(str(e) for e in list_vocab)  #class 'str'\n",
        "     \n",
        "     self.busc.buscar(self.temas)\n",
        "        \n",
        "     complej_indices=self.busc.complex_index\n",
        "     complej_mediana = np.median(complej_indices)\n",
        "\n",
        "     indice_simi2= self.busc.indices_sim\n",
        "     simi_c = indice_simi2.data\n",
        "     simi_median=np.median(simi_c)\n",
        "    \n",
        "     diff =abs(self.complej_usr-complej_mediana)\n",
        "     anti_complej= 1- diff\n",
        "     comp=(anti_complej+simi_median)/2\n",
        "   \n",
        "     if comp > self.rwd_th:\n",
        "       rwd=1\n",
        "     else:\n",
        "       rwd=0\n",
        "\n",
        "     self.busc.comps_complex()\n",
        "     self.busc.get_vectors()\n",
        "     obs= self.busc.vectores  #numpy.ndarray\n",
        "     self.rwd_acc += rwd\n",
        "     self.step_counter += 1\n",
        "     # Hacerlo en ventanas, no solo al inicio\n",
        "     done = True if self.step_counter > 10 and self.rwd_acc < self.step_counter * 0.5 else False\n",
        "     self.info = {\"Reward\": rwd, \"Query\": self.temas,\n",
        "             \"Complexity\": complej_mediana, \"Similarity\": simi_median}\n",
        "\n",
        "     return obs, rwd, done, self.info\n",
        "\n",
        "   def reset(self):\n",
        "     self.step_counter = 0\n",
        "     self.rwd_acc = 0\n",
        "     obs, rwd, done, self.info = self.step(self.action_space.sample())\n",
        "     return obs\n",
        "\n",
        "   def render(self):\n",
        "       print(self.info)\n",
        "   \n",
        "class Buscador:\n",
        " \n",
        "        def __init__(self,db,complej_tipo):\n",
        "\n",
        "           self.conversations = db[\"CONVERSATION\"]\n",
        "           self.complejidades = db[\"Standardize\"]  \n",
        "           self.vectorizer = TfidfVectorizer()\n",
        "           self.db =db\n",
        "           self.complej_tipo=complej_tipo\n",
        "           self.indice = {}\n",
        "           self.indices_sim = {}\n",
        "           self.complex_index=list() \n",
        "           self.vectores ={} \n",
        "           \n",
        "        def fit(self):\n",
        "          self.X = self.vectorizer.fit_transform(self.conversations)\n",
        "          vocab = self.vectorizer.vocabulary_.keys()\n",
        "          self.vocab_tam=len(vocab)\n",
        "          self.vocab_list = [*vocab]\n",
        "          self.vocab_arr =np.asarray(self.vocab_list)\n",
        "          self.vocab_lista= [[k] for k in vocab]\n",
        "       \n",
        "            \n",
        "        def buscar(self, topic):\n",
        "          q=[topic]\n",
        "          q_vec = self.vectorizer.transform(q)\n",
        "          self.indices_sim=cosine_similarity(self.X, q_vec,dense_output=False) \n",
        "          indi=self.indices_sim.todense()\n",
        "          vect=np.where(indi)\n",
        "          for i in range(len(vect)): #Get index\n",
        "            if i==0: \n",
        "             for j in range(len(vect[i])):\n",
        "               self.indice[j]=vect[i][j]\n",
        "                  \n",
        "          self.comps_complex()\n",
        "          return self.indice\n",
        "     \n",
        "        def get_vectors(self): \n",
        "          index_list=[]\n",
        "          index_list= list(self.indice.values())\n",
        "          State_index=self.X[index_list,:]\n",
        "          vectors=State_index.mean(axis=0)\n",
        "          self.vectores=np.squeeze(np.asarray(vectors))\n",
        "        \n",
        "        def comps_complex(self): \n",
        "          for i in range(len(self.indice)):#complexity index conversation\n",
        "            self.complex_index.append(self.complejidades[self.indice[i]])\n",
        "\n",
        "# nueva busqueda con temas y complejidad de usuario\n",
        "def new_search(env, topics, complexity):\n",
        "    env.set_topics(topics)\n",
        "    env.set_complexity(complexity)\n",
        "    obs = env.reset()\n",
        "    return obs, env\n"
      ],
      "metadata": {
        "id": "hKj75vVnEnrj"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "db = pd.read_excel(\"RECORDING SCRIPT FCE_D.xlsx\", sheet_name=\"Hoja1\")\n",
        "b=Buscador(db,\"tipo de complejidad de vocabulario\")\n",
        "b.fit()\n",
        "\n",
        "rwd_th = 0.5\n",
        "n_steps = 1000\n",
        "#usr_topics, usr_complexity = desde_interfaz()\n",
        "tema=['engine','car','school' ]#, 'food','school','beer','digital','phone','music','dance']\n",
        "usr_topics, usr_complexity = \" \".join(tema), 0.2"
      ],
      "metadata": {
        "id": "m8cUYN4GTdB_"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "e=Environment(b, rwd_th)\n",
        "obs,env = new_search(e, usr_topics, usr_complexity)\n",
        "\n",
        "#model= PPO(\"MlpPolicy\", env, verbose=100).learn(n_steps)\n",
        "model= A2C(\"MlpPolicy\", env, verbose=100).learn(n_steps)\n",
        "\n",
        "for _ in range(int(n_steps*0.2)): ## episodio\n",
        "\n",
        "    action = model.predict(obs) # consulta reformulada\n",
        "    obs, rwd, done, info = env.step(action)#_arr) #obs\n",
        "    if done: break\n",
        "    print(\"Agent Result:\", info)\n",
        "    if done:\n",
        "        break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-BfXtKSFR1FQ",
        "outputId": "4a941831-44b1-46bb-ac78-b3a54c518b36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "obs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p-DJRZFXLKJ2",
        "outputId": "0525a477-1eb2-4ce2-e518-45da1d5d267f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    }
  ]
}